---
title: "Analysis_IB_ThreatXCongruency"
author: "Ourouk Scylla Lucas Gautier"
date: '2023-11-10'
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

# Aim of the script

This script is the data analysis for the project
"IB_Threat*Congruency_Interaction". It use the last extraction of data collection which means n = 1922 participants who at least began the study.

OSF link of this project is <https://osf.io/xhc25/> (preregistration is
available at <https://osf.io/8ztcu>)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

list.of.packages <- c("dplyr", "tidyverse", "readr", "psych", "ggplot2", "TOSTER", "rsq", "questionr")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
invisible(lapply(list.of.packages, require, character.only = TRUE))

#rm(list=ls()) # clear workspace
rm("list.of.packages", "new.packages")

Initial_data <- read_csv("Transformed_Data/Dataset_Final_ThreatXCongruency.csv")%>%
  select(-"...1") %>%
  mutate(Check_Sound_str = case_when(Check_Sound == -0.5 ~ "No_Sound",
                                     Check_Sound == +0.5 ~ "Sound"))

```

# CodeBook:

## Participant identification

participant: a code name for each participant

ID: An ID number for identify each participant

ID_Yapper: The ID associated to each participant on the CrowdPanel
plateform

## Experimental Conditions

PrimaryTask: Which instructions participants have to perform in terms of
words\
- WhiteFocus = Count bounces of Whites squares\
- BlackFocus = Count bounces of Black squares

PrimaryTask_C: Which instructions participants have to perform in terms
of code\
- -0.5 = White squares bounce counting condition\
- +0.5 = Black squares bounce counting condition

Congruency: Is the unexpected element congruent or incongruent with task
settings in terms of words\
- Incongruent = The unexpected element is incongruent with task settings
(and ppts perform a inattentional blindness task with a low laod : 2
black squares and 2 white squares)\
- Congruent = The unexpected element is congruent with task settings
(and ppts perform a inattentional blindness task with a high laod : 4
black squares and 4 white squares)

Congruency_C: Is the unexpected element congruent or incongruent with
task settings in terms of code\
- -0.5 = The unexpected element is incongruent with task settings (and
ppts perform a inattentional blindness task with a low laod : 2 black
squares and 2 white squares)\
- +0.5 = The unexpected element is congruent with task settings (and
ppts perform a inattentional blindness task with a high laod : 4 black
squares and 4 white squares)

Threat: Which experimental condition participants are assigned at
(Threat VS control), in terms of words\
- Control = Control condition (no sound during the IB task)\
- Threat = Threat condition (an hazard alarm and screams during the IB
task)

Threat_C: Which experimental condition participants are assigned at
(Threat VS control), in terms of code\
- -0.5 = Control condition (a park)\
- +0.5 = Threat condition (a fire)

## Noticing

Noticing_Critic: If participant report having seen something during the
critical trial and report at least one characteristic of unexpected
elements (color, feature, motion)\
- 0 = Non noticer\
- 1 = Noticer who report at least one good feature of the unexpected
element

Noticing_Divided: If participant report having seen something during the
Divided attention trial and report at least one characteristic of
unexpected elements (color, feature, motion)\
- 0 = Non noticer\
- 1 = Noticer who report at least one good feature of the unexpected
element

Noticing_Full: If participant report having seen something during the
Full attention trial and report at least one characteristic of
unexpected elements (color, feature, motion)\
- 0 = Non noticer\
- 1 = Noticer who report at least one good feature of the unexpected
element

## Self Assessment Manikin (SAM)

This scale come from Sainz de Baranda et al., 2022 (SAM_UC3M4Safety)

### Pleasure

PleasureTrial1: Participant rating on the pleasure dimension of the Self
Assessment Manikin after the first trial of the IB task.\
- 1 = Negative feelings\
- 9 = Positive feelings

PleasureCritical: Participant rating on the pleasure dimension of the
Self Assessment Manikin after the critical trial of the IB task.\
- 1 = Negative feelings\
- 9 = Positive feelings

PleasureDivided: Participant rating on the pleasure dimension of the
Self Assessment Manikin after the divided attention trial of the IB
task.\
- 1 = Negative feelings\
- 9 = Positive feelings

### Arousal

ArousalTrial1: Participant rating on the arousal dimension of the Self
Assessment Manikin after the first trial of the IB task.\
- 1 = Calm\
- 9 = High excitation

ArousalCritical: Participant rating on the arousal dimension of the Self
Assessment Manikin after the critical trial of the IB task.\
- 1 = Calm\
- 9 = High excitation

ArousalDivided: Participant rating on the arousal dimension of the Self
Assessment Manikin after the divided attention trial of the IB task.\
- 1 = Calm\
- 9 = High excitation

### Sense of control

SenseControlTrial1: Participant rating on the sense of control dimension
of the Self Assessment Manikin after the first trial of the IB task.\
- 1 = Lack of control\
- 9 = Plenty of control

SenseControlCritical: Participant rating on the sense of control
dimension of the Self Assessment Manikin after the critical trial of the
IB task.\
- 1 = Lack of control\
- 9 = Plenty of control

SenseControlDivided: Participant rating on thesense of control dimension
of the Self Assessment Manikin after the divided attention trial of the
IB task.\
- 1 = Lack of control\
- 9 = Plenty of control

## Bounce-counting performance

Count_Trial1: Number of bounces counted during Trial1

Count_TrialCritic: Number of bounces counted during Critical Trial

Count_TrialDivided: Number of bounces counted during Divided Attention
Trial

Error_Trial1: absolute value of the difference between the real number
of bounce and what the participant reports for Trial 1

Error_TrialCritic: absolute value of the difference between the real
number of bounce and what the participant reports for the Critical Trial

Error_TrialDivided: absolute value of the difference between the real
number of bounce and what the participant reports for the Divided
Attention Trial

## Anxiety scales

### Anxiety scale Pre-test

Participants answers on the anxiety scale at the beginning of the
experiment:\
- Angry_pretest: Participant answer on the angry item from the anxiety
scale ("I currently feel angry"). Responses on a 7-likert scale, from 1
= "Not at all" to 7 = "Extremely".\
- Anxious_pretest: Participant answer on the anxious item from the
anxiety scale ("I currently feel anxious"). Responses on a 7-likert
scale, from 1 = "Not at all" to 7 = "Extremely".\
- Happy_pretest: Participant answer on the happy item from the anxiety
scale ("I currently feel happy"). Responses on a 7-likert scale, from 1
= "Not at all" to 7 = "Extremely".\
- Depressed_pretest: Participant answer on the depressed item from the
anxiety scale ("I'm currently feeling depressed"). Responses on a
7-likert scale, from 1 = "Not at all" to 7 = "Extremely".\
- Tense_pretest: Participant answer on the tense item from the anxiety
scale ("I'm currently feeling tense"). Responses on a 7-likert scale,
from 1 = "Not at all" to 7 = "Extremely".\
- Calm_pretest: Participant answer on the calm item from the anxiety
scale ("I'm currently feeling calm"). Responses on a 7-likert scale,
from 1 = "Not at all" to 7 = "Extremely".\
- Stressed_pretest: Participant answer on the stressed item from the
anxiety scale ("I feel stressed at the moment"). Responses on a 7-likert
scale, from 1 = "Not at all" to 7 = "Extremely".\
- Nervous_pretest: Participant answer on the nervous item from the
anxiety scale ("I'm currently feeling nervous"). Responses on a 7-likert
scale, from 1 = "Not at all" to 7 = "Extremely".

### Anxiety scale Post-test

Participants answers on the anxiety scale after the IB task:\
- Angry: Participant answer on the angry item from the anxiety scale ("I
currently feel angry"). Responses on a 7-likert scale, from 1 = "Not at
all" to 7 = "Extremely".\
- Anxious: Participant answer on the anxious item from the anxiety scale
("I currently feel anxious"). Responses on a 7-likert scale, from 1 =
"Not at all" to 7 = "Extremely".\
- Happy: Participant answer on the happy item from the anxiety scale ("I
currently feel happy"). Responses on a 7-likert scale, from 1 = "Not at
all" to 7 = "Extremely".\
- Depressed: Participant answer on the depressed item from the anxiety
scale ("I'm currently feeling depressed"). Responses on a 7-likert
scale, from 1 = "Not at all" to 7 = "Extremely".\
- Tense: Participant answer on the tense item from the anxiety scale
("I'm currently feeling tense"). Responses on a 7-likert scale, from 1 =
"Not at all" to 7 = "Extremely".\
- Calm: Participant answer on the calm item from the anxiety scale ("I'm
currently feeling calm"). Responses on a 7-likert scale, from 1 = "Not
at all" to 7 = "Extremely".\
- Stressed: Participant answer on the stressed item from the anxiety
scale ("I feel stressed at the moment"). Responses on a 7-likert scale,
from 1 = "Not at all" to 7 = "Extremely".\
- Nervous: Participant answer on the nervous item from the anxiety scale
("I'm currently feeling nervous"). Responses on a 7-likert scale, from 1
= "Not at all" to 7 = "Extremely".

FearScore_pre: A factorial composite score of 4 anxiety items (Tense,
Anxious, Nervous, Stressed) measured at the beginning of the experiment,
using a Bartlett method

FearScore_post: A factorial composite score of 4 anxiety items (Tense,
Anxious, Nervous, Stressed) measured after the experimental induction,
using a Bartlett method

FearScore: The difference between the anxiety factorial score after the
experimental induction and at the beginning of the experiment. Higher
scores reflect an increasing of the anxiety feelings at the
post-measurement in comparison to the pre-measurement (FearScore_post -
FearScore_pre)

FearMean_pre: A composite score of 4 anxiety items (Tense, Anxious,
Tense, Stressed) measured at the beginning of the experiment, using a
mean calculation rather than a factorial score

FearMean_post: A composite score of 4 anxiety items (Tense, Anxious,
Tense, Stressed) after the experimental induction, using a mean
calculation rather than a factorial score

FearMean: The difference between the anxiety mean score after the
experimental induction and at the beginning of the experiment. Higher
scores reflect an increasing of the anxiety feelings at the
post-measurement in comparison to the pre-measurement (FearMean_post -
FearMean_pre)

## Exclusion variables

-   SoundCalibration: Check whether participants correctly heard sounds
    after sound calibration for this experiment. On this question
    participants who respond '1' were redirected to the next
    "Sound_Problem" question, whereas participants who respond '2' or
    '3' went directly to the Inattentional blindness task. Responses on
    this scale were:
    -   NoSound: "I can't hear any sound."
    -   SoftSound: "I can hear the sound but it doesn't seem unpleasant
        to me even though my computer is at maximum volume."
    -   LoudSound: "I can hear the sound at a level that I personally
        find unpleasant."
-   SoundProblem: Participants who reported a problem on the
    "Sound_Calibration" question were redirected to this question in
    order to resolve their sound problem. Then if they responded '2' to
    this item, they were redirected to the "Sound_Calibration"
    questions. In an other way, they were directed to the end of the
    survey, stoping the experiment. Responses on this scale were:
    -   NotSolved: "I have a sound problem: end this experiment."
    -   Solved: "I've solved my sound problem: restart the volume
        calibration."

Check_Sound: Did participants hear any sound during the experiment -
-0.5 = Participants did not hear any sound\
- +0.5 = Participant heard some sounds

Check_Uncomfort: Did participants hear these sound at an uncomfortable
level - -0.5 = Sound level was not uncomfortable\
- +0.5 = Sound level was uncomfortable

Check_Volume: Did participants change the volume of their computer after
the sound calibration - -0.5 = Participants changed their sound level\
- +0.5 = Participants do not change their sound level

Knew: If participants have already done exactly the same task as this
dynamic inattentional blindness task\
- -0.5 = Never made exactly this task\
- +0.5 = Ever made exactly this task

KnewTask: If participants have already done a similar task but not
exactly the same one\
- -0.5 = No task knowledge\
- +0.5 = Task knowledge

KnewIB: If participants knew the inattentional blindness phenomenon
befor to run the experiment\
- -0.5 = No IB knowledge\
- +0.5 = IB knowledge

## Scarcity variables

Subjective_SES: Participant self placement on the McArthur Subjective
SES scale. A 10-point scale - 1 = the lowest social class in the
society - 10 = the highest social class in the society

Pay_Distance: The number of days in which participant will receive a
large amount of money - 1 = participant will be paid in the next day -
31 = participant will be paid in 31 day

Pay_Amount: The amount of money participant will receive the next time
he.she will be paid

Pay_Month: The amount of money participants receive each month (by
adding up their own money and that of their dependents)

Household_Nb: The number of people in the household who live with this
amount of money.

Perceived Economic Scarcity Scale: Participants respond to this scale in
a 7-point Likert Scale from 1 = Not at all, to 7 = Extremely - PESS1: My
income is low compared to others - PESS2: I feel that I have less money
than I need - PESS3: I find it difficult to pay my bills and basic
needs - PESS4: My income is insufficient to live decently - PESS5: I do
not have enough money to cover all my monthly expenses - PESS6: My
limited income and savings make me uncertain about my future - PESS7: I
can't stop thinking about the lack of money - PESS8: I worry about not
having enough money

## Demographics

Age: Participant self rating on age

Gender: Participant gender self identification\
- 1 = Woman self identification\
- 2 = Man self identification\
- 3 = None of these

Town: The town where participants live in

Country: The country participant live in

Studies: The highest level of education achieved by the participants -
No qualification - Secondary schools certificate - CAP (certificate of
professional competence) or BEP (Professional Studies Certificate) -
Baccalaureate - BAC+1 - BAC+2 - BAC+3 - BAC+4 - BAC+5 - BAC+6 - BAC+8 -
more than BAC+8

CSP: Participant occupation - 1 = Farmer, farm operator - 2 =
Craftsperson, shopkeeper, business owner - 3 = Executive and higher
intellectual profession - 4 = Intermediate profession (e.g. teacher,
nurse, social worker, etc.) - 5 = salaried employee - 6 = Manual
worker - 7 = Retired - 8 = Student or in educational training - 9 = Not
in employment or military - 10 = Don't know or can't answer - 11 = Other

CSP_Other: If participant declare another occupation, they can fill in a
blank space to specify it.

Writing_Script_C: Do participant know any script that do not follows the
Latin script (from left to right and up to down script). Another code
for this variable

Writing_Script: Do participant know any script that do not follows the
Latin script (from left to right and up to down script). Another code
for this variable - LatinScript = No - OtherScript = Yes

Writing_Language: If participant declare another script, they can fill
in a blank space to specify it.

Game_Feelings: A blank space in which participants can add any feeling
about this experiment

# Data exclusion

```{r Data exclusion, include = FALSE}

tmp <- df <- Initial_data

# To count the number of NA in each column
# sapply(df, function(x) sum(is.na(x)))

tmp <- tmp %>%
  filter(!is.na(TIME_total)) %>%
  filter(SoundCalibration == "SoftSound" | SoundCalibration == "LoudSound")%>% 
  filter(Check_Sound == +0.5 & Threat == "Threat" | Threat == "Control") %>%
  filter(Knew == -0.5) 


Incong_df <- tmp %>%
  filter(Congruency == "Incongruent") %>%
  mutate(Mad_Incong = case_when(Congruency == "Incongruent" & (Error_TrialCritic >= (median(Error_TrialCritic)+3*mad(Error_TrialCritic))) ~ "Out_Mad", 
                                Congruency == "Incongruent" & (Error_TrialCritic <= (median(Error_TrialCritic)+3*mad(Error_TrialCritic))) ~ "In_Mad"))

Cong_df <- tmp %>%
  filter(Congruency == "Congruent") %>%
  mutate(Mad_Cong = case_when(Congruency == "Congruent" & (Error_TrialCritic >= (median(Error_TrialCritic)+3*mad(Error_TrialCritic))) ~ "Out_Mad", 
                              Congruency == "Congruent" & (Error_TrialCritic <= (median(Error_TrialCritic)+3*mad(Error_TrialCritic))) ~ "In_Mad"))

tmp <- combine(Cong_df, Incong_df) %>%
  mutate(Mad_Cong = ifelse(is.na(Mad_Cong), "Not_Concerned", Mad_Cong),
         Mad_Incong = ifelse(is.na(Mad_Incong), "Not_Concerned", Mad_Incong)) %>%
  filter(Mad_Cong == "In_Mad" | Mad_Incong == "In_Mad")

df <- tmp
rm(tmp)

# sum(is.na(Initial_data$TIME_total))
# table(Initial_data$SoundCalibration)[["NoSound"]]
# table(Initial_data$Threat, Initial_data$Check_Sound_str)["Threat", "No_Sound"]
# table(Initial_data$Knew)[[2]]
# table(Incong_df$Mad_Incong)[["Out_Mad"]]
# table(Cong_df$Mad_Cong)[["Out_Mad"]]


```

Here, we removed some participants according to exclusion rules defined
in our pre-registration. These exclusions means:

-   n = `r sum(is.na(Initial_data$TIME_total))` participants that did
    not complete the study entirely
-   n = `r table(Initial_data$SoundCalibration)[["NoSound"]]`
    participants who report having sound problems during the calibration
    phase
-   n =
    `r table(Initial_data$Threat, Initial_data$Check_Sound_str)["Threat", "No_Sound"]`
    participants who didn't heard sounds during the IB task in the
    threatening condition (however who decided to keep n =
    `r table(Initial_data$Threat, Initial_data$Check_Sound_str)["Control", "Sound"]`
    participants who report having hear some sounds in the control
    condition even if no sound was played)
-   n = `r table(Initial_data$Knew)[[2]]` participants who report having
    previously do exactly the same task
-   n = `r table(Cong_df$Mad_Cong)[["Out_Mad"]]` and n =
    `r table(Incong_df$Mad_Incong)[["Out_Mad"]]` participants whose
    performance on the bounce-counting task is higher than 3 Mad from
    the rest of the sample on the critical trial respectively in the
    congruent and in the incongruent conditions (this bounce-counting
    performance represents the difference between participant's
    performance and the real number of bounces in the critical trial)

Even if a total number of n = `r nrow(Initial_data)` participants
started the experiment, we get only n =
`r nrow(Initial_data)-sum(is.na(Initial_data$TIME_total))` complete
data. In addition, after applying the exclusion rules defined in our
preregistration, the final number of participants to run our analysis is
n = `r nrow(df)`

# Analysis

## Manipulation check

### Anxiety feelings

To check the effect of our manipulation on these variables, we will
apply a Bonferroni Correction on these 3 analysis (Anxiety feelings,
Arousal, Pleasure): .05/3 = 0.017

```{r TOST boundaries, eval=FALSE}

# For Equivalence testing on the effect of our experimental manipulation, use a SESOI of d = .20 seems appropriate given our sample size and the Bonferroni correction:

powerTOSTtwo(alpha = .017, statistical_power = .95, N = 1600)

powerTOSTone(alpha = .017, statistical_power = .95, N = 800)


```


```{r Anxiety Manip check}

alpha_ManipCheck <- 0.05/3

# Did participants differ in there anxiety level at the beginning of the experiment ? 

Anxiety_Pretest_Check <- lm(FearScore_pre ~ Threat_C, data = df)
summary(Anxiety_Pretest_Check)
rsq.partial(Anxiety_Pretest_Check)

#TOSTtwo(alpha = alpha_ManipCheck, low_eqbound_d = -0.20, high_eqbound_d = 0.20)


# Did participants differ in there anxiety level at the end of the experiment ? 

Anxiety_Posttest_Check <- lm(FearScore_post ~ Threat_C, data = df)
summary(Anxiety_Posttest_Check)
rsq.partial(Anxiety_Posttest_Check)

#TOSTtwo(alpha = alpha_ManipCheck, low_eqbound_d = -0.20, high_eqbound_d = 0.20)


# Do the experimental manipulation have an effect on anxiety evolution between pre and post-measurements ?

Anxiety_Evolution_Check <- lm(FearScore ~ Threat_C, data = df)
summary(Anxiety_Evolution_Check)
rsq.partial(Anxiety_Evolution_Check)

#TOSTtwo(alpha = alpha_ManipCheck, low_eqbound_d = -0.20, high_eqbound_d = 0.20)


# Is the task effective for increase the level of anxiety in the threat condition ?

df_Threat <- df %>%
  filter(Threat=="Threat")
  
Anxiety_Check_Threat <- lm(FearScore ~ 1, data = df_Threat)
summary(alpha = alpha_ManipCheck, Anxiety_Check_Threat)

#TOSTone(low_eqbound_d = -0.20, high_eqbound_d = 0.20)

# Is the task ineffective for increase the level of anxiety in the control condition ?

df_Control <- df %>%
  filter(Threat=="Control")
  
Anxiety_Check_Control <- lm(FearScore ~ 1, data = df_Control)
summary(Anxiety_Check_Control)

#TOSTone(alpha = alpha_ManipCheck, low_eqbound_d = -0.20, high_eqbound_d = 0.20)

```


### Arousal

To check the effect of our manipulation on these variables, we will
apply a Bonferroni Correction on these 3 analysis (Anxiety feelings,
Arousal, Pleasure): .05/3 = 0.017


```{r Arousal Manip check}

# Do participants differ on their arousal level after the critical trial (before being asked about the presence of an unexpected element) ?

Arousal_Critical_Check<- lm(ArousalCritical ~ Threat_C, data = df)
summary(Arousal_Critical_Check)
rsq.partial(Arousal_Critical_Check)

#TOSTtwo(alpha = alpha_ManipCheck, low_eqbound_d = -0.20, high_eqbound_d = 0.20)


```

### Pleasure

To check the effect of our manipulation on these variables, we will
apply a Bonferroni Correction on these 3 analysis (Anxiety feelings,
Arousal, Pleasure): .05/3 = 0.017


```{r Pleasure Manip check}

# Do participants differ on their pleasure level after the critical trial (before being asked about the presence of an unexpected element) ?

Pleasure_Critical_Check<- lm(PleasureCritical ~ Threat_C, data = df)
summary(Pleasure_Critical_Check)
rsq.partial(Pleasure_Critical_Check)

#TOSTtwo(alpha = alpha_ManipCheck, low_eqbound_d = -0.20, high_eqbound_d = 0.20)


```



### Sense of Control: Exploratory analysis

```{r Sense of Control Manip check}

# Do participants differ on their arousal level after the critical trial (before being asked about the presence of an unexpected element) ?

SenseControl_Critical_Check<- lm(SenseControlCritical ~ Threat_C, data = df)
summary(SenseControl_Critical_Check)
rsq.partial(SenseControl_Critical_Check)

#TOSTtwo(low_eqbound_d = -0.20, high_eqbound_d = 0.20)


```



## Threat effect on noticing


```{r Congruency dataframes, include=FALSE}

rm(Cong_df, Incong_df)

# Build the Congruent data frame
df_Cong <- df %>%
  filter(Congruency == "Congruent")

# Build the Incongruent data frame
df_Incong <- df %>%
  filter(Congruency == "Incongruent")

```


### Threat: Congruent unexpected element

```{r Effect of threat on noticing_Congruent}

# Do the threatening manipulation have an effect on noticing rate for the congruent unexpected element ?

Threat_Cong <- glm(Noticing_Critic ~ Threat_C , family ="binomial", data = df_Cong)
summary(Threat_Cong)
odds.ratio(Threat_Cong) # Calculate ODD RATIO of the model


# With Covariates
Threat_Cong_Cov <- glm(Noticing_Critic ~ Threat_C + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df_Cong)
summary(Threat_Cong_Cov)
odds.ratio(Threat_Cong_Cov) # Calculate ODD RATIO of the model
rsq.partial(Threat_Cong_Cov) # Calculate an equivalent of R²p of the model

# Equivalence testing
#TOSTtwo.prop(alpha = .05,  prop1 =, prop2 =, n1 = , n2 =  ,low_eqbound = -.20, high_eqbound = .20)

```


### Threat: Incongruent unexpected element

```{r Effect of threat on noticing_Incongruent}

# Do the threatening manipulation have an effect on noticing rate for the incongruent unexpected element ?

Threat_Incong <- glm(Noticing_Critic ~ Threat_C , family ="binomial", data = df_Incong)
summary(Threat_Incong)
odds.ratio(Threat_Incong) # Calculate ODD RATIO of the model


# With Covariates
Threat_Incong_Cov <- glm(Noticing_Critic ~ Threat_C + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df_Incong)
summary(Threat_Incong_Cov)
odds.ratio(Threat_Incong_Cov) # Calculate ODD RATIO of the model
rsq.partial(Threat_Incong_Cov) # Calculate an equivalent of R²p of the model

# Equivalence testing
#TOSTtwo.prop(alpha = .05,  prop1 =, prop2 =, n1 = , n2 =  ,low_eqbound = -.20, high_eqbound = .20)

```

### Threat: Threat X Congruency interaction

According to our preregistration, we will use a p-value threshold of aplha = 0.01 on this analysis

```{r Threat X Congruency interaction}

# Do the threatening manipulation interact with congruency to predict noticing rate using the whole dataframe (with participants who belong both to the congruent and the incongruent conditions) ?

ThreatXCongruency <- glm(Noticing_Critic ~ Threat_C * Congruency_C , family ="binomial", data = df)
summary(ThreatXCongruency)
odds.ratio(ThreatXCongruency) # Calculate ODD RATIO of the model
rsq.partial(ThreatXCongruency) # Calculate an equivalent of R²p of the model


# With Covariates
ThreatXCongruency_Cov <- glm(Noticing_Critic ~ Threat_C * Congruency_C + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df)
summary(ThreatXCongruency_Cov)
odds.ratio(ThreatXCongruency_Cov) # Calculate ODD RATIO of the model
rsq.partial(ThreatXCongruency_Cov) # Calculate an equivalent of R²p of the model


```

################################################"



## Anxiety effect on notincing

### Anxiety/Arousal: correlations

```{r Anxiety/Arousal Correlations}

# Is there a correlation between Anxiety (the pre and post-measurement difference) and Arousal levels (measured after the critical trial) ?

Cor_Anxiety_Arousal <- cor.test(df$FearScore, df$ArousalCritical) 
# Cor_Anxiety_Arousal <- cor.test(df$FearScore_post, df$ArousalCritical) 
print(Cor_Anxiety_Arousal)

alpha_AnxietyArousal <- ifelse(Cor_Anxiety_Arousal[["p.value"]]<= 0.05 & Cor_Anxiety_Arousal[["estimate"]][["cor"]]<= 0.5, 0.05, (0.05/2))

# We can also use the correlation above which do not use the evolution score of anxiety but only the post test score that better reflect the Arousal measurement:
# Cor_Anxiety_Arousal_Post <- cor.test(df$FearScore_post, df$ArousalCritical) 
#print(Cor_Anxiety_Arousal_Post)

```

Since the correlation between the anxiety score (difference between pre and post measurements) and the arousal level after the critical trial is `r ifelse(Cor_Anxiety_Arousal[["p.value"]]<= 0.05 ,"significant", "not significant")`, and the link between these variable is `r ifelse(Cor_Anxiety_Arousal[["estimate"]][["cor"]]<= 0.5 ,"lesser", "higher")` than *r* = 0.50 (*r* = `r round(Cor_Anxiety_Arousal[["estimate"]][["cor"]], digit = 2)`, t(`r Cor_Anxiety_Arousal[["parameter"]][["df"]]`) = `r round(Cor_Anxiety_Arousal[["statistic"]][["t"]], digit=2)`, *p* `r ifelse((Cor_Anxiety_Arousal[["p.value"]])<= 0.001 ,"< 0.001", ifelse((Cor_Anxiety_Arousal[["p.value"]])<= 0.01 ,"< 0.01", paste0("= ", round((Cor_Anxiety_Arousal[["p.value"]]), digit = 2))))`, CI 95% [`r round(Cor_Anxiety_Arousal[["conf.int"]][[1]], digit = 2)`, `r round(Cor_Anxiety_Arousal[["conf.int"]][[2]], digit = 2)`]), according to our preregistration we will use a significance alpha threshold of alpha = `r ifelse(Cor_Anxiety_Arousal[["estimate"]][["cor"]]<= 0.5 ,"0.05 (without applying any correction)", ".05/2 = .025 (to correct for multiple analysis)")` for the next analyses: the effect of Anxiety and Arousal on noticing rates.


### Anxiety/Arousal: Congruent unexpected element

```{r Effect of Anxiety/Arousal on noticing_Congruent}

# Anxiety level

# Do the anxiety level have an effect on noticing rate for the congruent unexpected element ?

Anxiety_Cong <- glm(Noticing_Critic ~ FearScore , family ="binomial", data = df_Cong)
summary(Anxiety_Cong)
odds.ratio(Anxiety_Cong) # Calculate ODD RATIO of the model


# With Covariates
Anxiety_Cong_Cov <- glm(Noticing_Critic ~ FearScore + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df_Cong)
summary(Anxiety_Cong_Cov)
odds.ratio(Anxiety_Cong_Cov) # Calculate ODD RATIO of the model
rsq.partial(Anxiety_Cong_Cov) # Calculate an equivalent of R²p of the model

# Equivalence testing
#Cor_Noticing_Anxiety_Cong <- cor.test(df_Cong$Noticing_Critic, df_Cong$FearScore) 
#TOSTr(r = Cor_Noticing_Anxiety_Cong[["estimate"]][["cor"]], n = nrow(df_Cong), alpha = alpha_AnxietyArousal, low_eqbound_r = -.20, high_eqbound_r = .20)

##############################################################

# Arousal level

# Do the arousal level have an effect on noticing rate for the congruent unexpected element ?

Arousal_Cong <- glm(Noticing_Critic ~ ArousalCritical , family ="binomial", data = df_Cong)
summary(Arousal_Cong)
odds.ratio(Arousal_Cong) # Calculate ODD RATIO of the model


# With Covariates
Arousal_Cong_Cov <- glm(Noticing_Critic ~ ArousalCritical + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df_Cong)
summary(Arousal_Cong_Cov)
odds.ratio(Arousal_Cong_Cov) # Calculate ODD RATIO of the model
rsq.partial(Arousal_Cong_Cov) # Calculate an equivalent of R²p of the model

# Equivalence testing
#Cor_Noticing_Arousal_Cong <- cor.test(df_Cong$Noticing_Critic, df_Cong$ArousalCritical) 
#TOSTr(r = Cor_Noticing_Arousal_Cong[["estimate"]][["cor"]], n = nrow(df_Cong), alpha = alpha_AnxietyArousal, low_eqbound_r = -.20, high_eqbound_r = .20)

```


### Anxiety/Arousal: Incongruent unexpected element

```{r Effect of Anxiety/Arousal on noticing_Incongruent}

# Anxiety level

# Do the anxiety level have an effect on noticing rate for the incongruent unexpected element ?

Anxiety_Incong <- glm(Noticing_Critic ~ FearScore , family ="binomial", data = df_Incong)
summary(Anxiety_Incong)
odds.ratio(Anxiety_Incong) # Calculate ODD RATIO of the model


# With Covariates
Anxiety_Incong_Cov <- glm(Noticing_Critic ~ FearScore + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df_Incong)
summary(Anxiety_Incong_Cov)
odds.ratio(Anxiety_Incong_Cov) # Calculate ODD RATIO of the model
rsq.partial(Anxiety_Incong_Cov) # Calculate an equivalent of R²p of the model

# Equivalence testing
#Cor_Noticing_Anxiety_Incong <- cor.test(df_Incong$Noticing_Critic, df_Incong$FearScore) 
#TOSTr(r = Cor_Noticing_Anxiety_Incong[["estimate"]][["cor"]], n = nrow(df_Incong), alpha = alpha_AnxietyArousal, low_eqbound_r = -.20, high_eqbound_r = .20)

##############################################################

# Arousal level

# Do the arousal level have an effect on noticing rate for the incongruent unexpected element ?


Arousal_Incong <- glm(Noticing_Critic ~ ArousalCritical , family ="binomial", data = df_Incong)
summary(Arousal_Incong)
odds.ratio(Arousal_Incong) # Calculate ODD RATIO of the model


# With Covariates
Arousal_Incong_Cov <- glm(Noticing_Critic ~ ArousalCritical + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df_Incong)
summary(Arousal_Incong_Cov)
odds.ratio(Arousal_Incong_Cov) # Calculate ODD RATIO of the model
rsq.partial(Arousal_Incong_Cov) # Calculate an equivalent of R²p of the model

# Equivalence testing
#Cor_Noticing_Arousal_Incong <- cor.test(df_Incong$Noticing_Critic, df_Incong$ArousalCritical) 
#TOSTr(r = Cor_Noticing_Arousal_Incong[["estimate"]][["cor"]], n = nrow(df_Incong), alpha = alpha_AnxietyArousal, low_eqbound_r = -.20, high_eqbound_r = .20)

```


### Anxiety/Arousal: Threat X Congruency interaction

According to our preregistration, we will use a p-value threshold of aplha = 0.01 on this analysis

```{r Anxiety/Arousal X Congruency interaction}

# Anxiety level

# Do the anxiety level interact with congruency to predict noticing rate using the whole dataframe (with participants who belong both to the congruent and the incongruent conditions) ?

AnxietyXCongruency <- glm(Noticing_Critic ~ FearScore * Congruency_C , family ="binomial", data = df)
summary(AnxietyXCongruency)
odds.ratio(AnxietyXCongruency) # Calculate ODD RATIO of the model
rsq.partial(AnxietyXCongruency) # Calculate an equivalent of R²p of the model


# With Covariates
AnxietyXCongruency_Cov <- glm(Noticing_Critic ~ FearScore * Congruency_C + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df)
summary(AnxietyXCongruency_Cov)
odds.ratio(AnxietyXCongruency_Cov) # Calculate ODD RATIO of the model
rsq.partial(AnxietyXCongruency_Cov) # Calculate an equivalent of R²p of the model

############################################################################

# Arousal level

# Do the arousal level interact with congruency to predict noticing rate using the whole dataframe (with participants who belong both to the congruent and the incongruent conditions) ?

ArousalXCongruency <- glm(Noticing_Critic ~ ArousalCritical * Congruency_C , family ="binomial", data = df)
summary(ArousalXCongruency)
odds.ratio(ArousalXCongruency) # Calculate ODD RATIO of the model
rsq.partial(ArousalXCongruency) # Calculate an equivalent of R²p of the model


# With Covariates
ArousalXCongruency_Cov <- glm(Noticing_Critic ~ ArousalCritical * Congruency_C + PrimaryTask_C + Error_TrialCritic , family ="binomial", data = df)
summary(ArousalXCongruency_Cov)
odds.ratio(ArousalXCongruency_Cov) # Calculate ODD RATIO of the model
rsq.partial(ArousalXCongruency_Cov) # Calculate an equivalent of R²p of the model

```

## Interaction Effect on noticing (Threat X Anxiety)

### Interaction: Congruent unexpected element

```{r Interaction Threat X Anxiety/Arousal_Congruent}

# Anxiety level

# Do the threatening manipulation interact with anxiety level to predict noticing rate for the congruent unexpected element ?

Interact_ThreatXAnxiety_Cong <- glm(Noticing_Critic ~ Threat_C * FearScore, family ="binomial", data = df_Cong)
summary(Interact_ThreatXAnxiety_Cong)
odds.ratio(Interact_ThreatXAnxiety_Cong) # Calculate ODD RATIO of the model
rsq.partial(Interact_ThreatXAnxiety_Cong) # Calculate an equivalent of R²p of the model


############################################################################

# Arousal level

# Do the threatening manipulation interact with arousal level to predict noticing rate for the congruent unexpected element ?

Interact_ThreatXArousal_Cong <- glm(Noticing_Critic ~ Threat_C *ArousalCritical, family ="binomial", data = df_Cong)
summary(Interact_ThreatXArousal_Cong)
odds.ratio(Interact_ThreatXArousal_Cong) # Calculate ODD RATIO of the model
rsq.partial(Interact_ThreatXArousal_Cong) # Calculate an equivalent of R²p of the model


```

### Interaction: Incongruent unexpected element

```{r Interaction Threat X Anxiety/Arousal_Incongruent}

# Anxiety level

# Do the threatening manipulation interact with Anxiety level to predict noticing rate for the incongruent unexpected element ?

Interact_ThreatXAnxiety_Incong <- glm(Noticing_Critic ~ Threat_C * FearScore, family ="binomial", data = df_Incong)
summary(Interact_ThreatXAnxiety_Incong)
odds.ratio(Interact_ThreatXAnxiety_Incong) # Calculate ODD RATIO of the model
rsq.partial(Interact_ThreatXAnxiety_Incong) # Calculate an equivalent of R²p of the model


############################################################################

# Arousal level

# Do the threatening manipulation interact with arousal level to predict noticing rate for the incongruent unexpected element ?

Interact_ThreatXArousal_Incong <- glm(Noticing_Critic ~ Threat_C *ArousalCritical, family ="binomial", data = df_Incong)
summary(Interact_ThreatXArousal_Incong)
odds.ratio(Interact_ThreatXArousal_Incong) # Calculate ODD RATIO of the model
rsq.partial(Interact_ThreatXArousal_Incong) # Calculate an equivalent of R²p of the model

```


### Interaction: Equivalence testing

#### TOST Anxiety: Congruent unexpected element

```{r TOST Noticing~Anxiety_Congruent}

# Control Condition

# Is the effect between Anxiety level and noticing in the control condition smaller than a SESOI for the congruent unexpected element (r = .20) ? (We pre-registered it will)

df_Control_Cong <- df %>%
  filter(Threat == "Control" & Congruency == "Congruent")

Cor_CtrlCond_Noticing_Anxiety_Cong <- cor.test(df_Control_Cong$Noticing_Critic, df_Control_Cong$FearScore) 
TOSTr(r = Cor_CtrlCond_Noticing_Anxiety_Cong[["estimate"]][["cor"]], n = nrow(df_Control_Cong), alpha = .025, low_eqbound_r = -.20, high_eqbound_r = .20)


# Threat Condition

# Is the effect between Anxiety level and noticing in the threatening condition smaller than a SESOI for the congruent unexpected element (r = .20) ? (We pre-registered it will not)

df_Threat_Cong <- df %>%
  filter(Threat == "Threat" & Congruency == "Congruent")

Cor_ThreatCond_Noticing_Anxiety_Cong <- cor.test(df_Threat_Cong$Noticing_Critic, df_Threat_Cong$FearScore) 
TOSTr(r = Cor_ThreatCond_Noticing_Anxiety_Cong[["estimate"]][["cor"]], n = nrow(df_Threat_Cong), alpha = .025, low_eqbound_r = -.20, high_eqbound_r = .20)

```


#### TOST Anxiety: Incongruent unexpected element

```{r TOST Noticing~Anxiety_Incongruent}

# Control Condition

# Is the effect between Anxiety level and noticing in the control condition smaller than a SESOI for the incongruent unexpected element (r = .20) ? (We pre-registered it will)

df_Control_Incong <- df %>%
  filter(Threat == "Control" & Congruency == "Incongruent")

Cor_CtrlCond_Noticing_Anxiety_Incong <- cor.test(df_Control_Incong$Noticing_Critic, df_Control_Incong$FearScore) 
TOSTr(r = Cor_CtrlCond_Noticing_Anxiety_Incong[["estimate"]][["cor"]], n = nrow(df_Control_Incong), alpha = .025, low_eqbound_r = -.20, high_eqbound_r = .20)


# Threat Condition

# Is the effect between Anxiety level and noticing in the threatening condition smaller than a SESOI for the incongruent unexpected element (r = .20) ? (We pre-registered it will not)

df_Threat_Incong <- df %>%
  filter(Threat == "Threat" & Congruency == "Incongruent")

Cor_ThreatCond_Noticing_Anxiety_Incong <- cor.test(df_Threat_Incong$Noticing_Critic, df_Threat_Incong$FearScore) 
TOSTr(r = Cor_ThreatCond_Noticing_Anxiety_Incong[["estimate"]][["cor"]], n = nrow(df_Threat_Incong), alpha = .025, low_eqbound_r = -.20, high_eqbound_r = .20)

```


#### TOST Exploratory: Arousal 

In order not to inflate type I error rates, we will use a alpha threshold of 0.01 for these exploratory equivalence analyses 

##### TOST Arousal: Congruent unexpected element

```{r TOST Noticing~Arousal_Congruent, eval=FALSE}

# Control Condition

# Is the effect between Anxiety level and noticing in the threatening condition smaller than a SESOI for the incongruent unexpected element (r = .20) ?

df_Control_Cong <- df %>%
  filter(Threat == "Control" & Congruency == "Congruent")

Cor_CtrlCond_Noticing_Arousal_Cong <- cor.test(df_Control_Cong$Noticing_Critic, df_Control_Cong$ArousalCritical) 
TOSTr(r = Cor_CtrlCond_Noticing_Arousal_Cong[["estimate"]][["cor"]], n = nrow(df_Control_Cong), alpha = .01, low_eqbound_r = -.20, high_eqbound_r = .20)


# Threat Condition

# Is the effect between Anxiety level and noticing in the threatening condition smaller than a SESOI for the congruent unexpected element (r = .20) ?

df_Threat_Cong <- df %>%
  filter(Threat == "Threat" & Congruency == "Congruent")

Cor_ThreatCond_Noticing_Arousal_Cong <- cor.test(df_Threat_Cong$Noticing_Critic, df_Threat_Cong$ArousalCritical) 
TOSTr(r = Cor_ThreatCond_Noticing_Arousal_Cong[["estimate"]][["cor"]], n = nrow(df_Threat_Cong), alpha = .01, low_eqbound_r = -.20, high_eqbound_r = .20)

```


##### TOST Arousal: Incongruent unexpected element

```{r TOST Noticing~Arousal_Incongruent, eval=FALSE}

# Control Condition

# Is the effect between Anxiety level and noticing in the control condition smaller than a SESOI for the incongruent unexpected element (r = .20) ?

df_Control_Incong <- df %>%
  filter(Threat == "Control" & Congruency == "Incongruent")

Cor_CtrlCond_Noticing_Arousal_Incong <- cor.test(df_Control_Incong$Noticing_Critic, df_Control_Incong$ArousalCritical) 
TOSTr(r = Cor_CtrlCond_Noticing_Arousal_Incong[["estimate"]][["cor"]], n = nrow(df_Control_Incong), alpha = .01, low_eqbound_r = -.20, high_eqbound_r = .20)


# Threat Condition

# Is the effect between Anxiety level and noticing in the threatening condition smaller than a SESOI for the incongruent unexpected element (r = .20) ?

df_Threat_Incong <- df %>%
  filter(Threat == "Threat" & Congruency == "Incongruent")

Cor_ThreatCond_Noticing_Arousal_Incong <- cor.test(df_Threat_Incong$Noticing_Critic, df_Threat_Incong$ArousalCritical) 
TOSTr(r = Cor_ThreatCond_Noticing_Arousal_Incong[["estimate"]][["cor"]], n = nrow(df_Threat_Incong), alpha = .01, low_eqbound_r = -.20, high_eqbound_r = .20)

```


## Bounce counting performance

### Counting: Congruent unexpected element

```{r Effect of Threat on counting performance_Congruent}

# Do the threatening manipulation have an impact on bounce counting performance in the high load task?

Counting_Cong <- lm(Error_TrialCritic ~ Threat_C, data = df_Cong)
summary(Counting_Cong)
rsq.partial(Counting_Cong)

# With Covariates
Counting_Cong_Cov <- lm(Error_TrialCritic ~ Threat_C + PrimaryTask_C, data = df_Cong)
summary(Counting_Cong_Cov)
rsq.partial(Counting_Cong_Cov) 


# Equivalence testing
#TOSTtwo(alpha = .05, low_eqbound_d = -0.30, high_eqbound_d = 0.30)

```


### Counting: Incongruent unexpected element

```{r Effect of Threat on counting performance_Incongruent}

# Do the threatening manipulation have an impact on bounce counting performance in the low load task?

Counting_Incong <- lm(Error_TrialCritic ~ Threat_C, data = df_Incong)
summary(Counting_Incong)
rsq.partial(Counting_Incong)

# With Covariates
Counting_Incong_Cov <- lm(Error_TrialCritic ~ Threat_C + PrimaryTask_C, data = df_Incong)
summary(Counting_Incong_Cov)
rsq.partial(Counting_Incong_Cov) 

# Equivalence testing
#TOSTtwo(alpha = .05, low_eqbound_d = -0.30, high_eqbound_d = 0.30)

```

### Counting: Threat X Congruency Interaction

According to other analyses, we will use a p-value threshold of aplha = 0.01 on this analysis

```{r Interaction Threat * Congruency on counting performance}

# Do the threatening manipulation interact with congruency to predict the bounce counting performance using the whole dataframe (with participants who belong both to the congruent and the incongruent conditions) ?

Counting_Interact <- lm(Error_TrialCritic ~ Threat_C * Congruency_C, data = df)
summary(Counting_Interact)
rsq.partial(Counting_Interact)

# With Covariates
Counting_Interact_Cov <- lm(Error_TrialCritic ~ Threat_C * Congruency_C + PrimaryTask_C, data = df)
summary(Counting_Interact_Cov)
rsq.partial(Counting_Interact_Cov) 

```

## Other Inattentional Blindness trials

We plan to analyse the effect of experimental conditions on noticing rates in the Divided attention and the full attention trials but we will do run these analysis in an exploratory way since we do not have precise hypothesis on these trials except for the same hypothesis we expect on the critical trial. However, we do not have planned these analyses in this pre-registration script.

## Multivers analysis

We plan to use this type of analysis to test the robustness of some effects according to multiple exclusion criterion, however, we do not have planned these analyses in this pre-registration script..

## Random forest analysis

We plan to maybe run conditional random forest analysis to analyse in an exploratory way the variables that best predict noticing rates on the several inattentional blindness trials. However, we do not have planned these analyses in this pre-registration script..


